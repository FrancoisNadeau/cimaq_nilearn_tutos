{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Decoding of a dataset after GLM fit for signal extraction\n",
    "\n",
    "Full step-by-step example of fitting a GLM to perform a decoding experiment.\n",
    "We use the data from one subject of the Haxby dataset.\n",
    "\n",
    "More specifically:\n",
    "\n",
    "1. Download the Haxby dataset.\n",
    "2. Extract the information to generate a glm representing the blocks of stimuli.\n",
    "3. Analyze the decoding performance using a classifier.\n",
    "\n",
    "To run this example, you must launch IPython via ``ipython\n",
    "--matplotlib`` in a terminal, or use the Jupyter notebook.\n",
    "    :depth: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch example Haxby dataset\n",
    "We download the Haxby dataset\n",
    "This is a study of visual object category representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fnadeau/myenv/lib/python3.7/site-packages/nilearn/datasets/__init__.py:89: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  \"Numpy arrays.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import nilearn\n",
    "import os\n",
    "import tarfile\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from bids_validator import BIDSValidator\n",
    "\n",
    "from fetch_difumo import fetch_difumo\n",
    "\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from os import listdir as ls\n",
    "from os.path import basename as bname\n",
    "from os.path import dirname as dname\n",
    "from os.path import expanduser as xpu\n",
    "from os.path import join as pjoin\n",
    "from pandas import DataFrame as df\n",
    "from tempfile import TemporaryDirectory as tmpdir\n",
    "from tempfile import TemporaryFile as tmpfile\n",
    "from tqdm import tqdm\n",
    "from typing import Union\n",
    "\n",
    "import loadutils as lu\n",
    "import sniffbytes as snif\n",
    "import scanzip as szip\n",
    "import shutil\n",
    "\n",
    "from nilearn import masking\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, plot_epi\n",
    "from nilearn.image import concat_imgs, mean_img\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "def lst_intersection(lst1, lst2):\n",
    "    '''\n",
    "    Source: https://www.geeksforgeeks.org/python-intersection-two-lists/\n",
    "    '''\n",
    "    return [value for value in lst1 if value in set(lst2)]\n",
    "\n",
    "def read_json(fpath:Union[str, os.PathLike]) -> dict:\n",
    "    with open(fpath, mode='r', encoding='UTF-8') as jfile:\n",
    "        jdict = json.load(jfile)\n",
    "    jfile.close()\n",
    "    return jdict\n",
    "\n",
    "cimaq_nov_dir = xpu('~/../../data/cisl/DATA/cimaq_20190901')\n",
    "cimaq_mar_dir = xpu('~/../../data/cisl/DATA/cimaq_03-19')\n",
    "events_path = xpu('~/../../data/cisl/DATA/cimaq_corrected_events/events')\n",
    "behav_path = xpu('~/../../data/cisl/DATA/cimaq_corrected_behavioural/behavioural')\n",
    "participants_desc = read_json(fpath=pjoin(cimaq_mar_dir, 'participants.json'))\n",
    "dataset_desc = read_json(fpath=pjoin(cimaq_mar_dir, 'dataset_description.json'))\n",
    "# post_scan_desc = read_json(fpath=pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/task_files/PostScanBehav_CIMAQ_memory.json'))\n",
    "# taskfile_headers = read_json(pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/task_files/TaskFile_headers_CIMAQ_memory.json'))\n",
    "# sorted(ls(pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/features/beta_maps')))\n",
    "task_results = pd.read_csv(pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/participants/TaskResults/fMRI_behavMemoScores.tsv'),\n",
    "                           sep='\\t')\n",
    "MemoTaskParticipantFile = pd.read_csv(pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/participants/MemoTaskParticipantFile.tsv'),\n",
    "                           sep='\\t')\n",
    "# MemoTaskParticipantFile\n",
    "# task_results.columns\n",
    "# sorted(ls(pjoin(cimaq_mar_dir, 'derivatives/CIMAQ_fmri_memory/data/participants/')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class participant_data:\n",
    "    from nilearn import masking\n",
    "    from nilearn.plotting import plot_stat_map, plot_anat, plot_img, plot_epi\n",
    "    from nilearn.image import concat_imgs, mean_img\n",
    "    def __init__(self):\n",
    "        cimaq_nov_dir = xpu('~/../../data/cisl/DATA/cimaq_20190901')\n",
    "        cimaq_mar_dir = xpu('~/../../data/cisl/DATA/cimaq_03-19')\n",
    "        events_path = xpu('~/../../data/cisl/DATA/cimaq_corrected_events/events')\n",
    "        behav_path = xpu('~/../../data/cisl/DATA/cimaq_corrected_behavioural/behavioural')\n",
    "#     def __init__(self, sub_id, mar_scans, nov_scans, mar_infos, nov_infos):\n",
    "    \n",
    "        # Load participants infos and indexing file\n",
    "        participants = pd.read_csv(pjoin(cimaq_mar_dir,\n",
    "                                         pjoin(cimaq_mar_dir,\n",
    "                                               'derivatives/CIMAQ_fmri_memory/data/participants/Participants_bids.tsv')),\n",
    "                                   sep = '\\t')\n",
    "        # Assing each participant to its double identifier\n",
    "        subjects = df(tuple(('sub-'+str(itm[0]), 'sub-'+str(itm[1])) for itm in\n",
    "                            tuple(zip(participants.participant_id, participants.pscid))),\n",
    "                      columns = ['mar_subs', 'nov_subs'])\n",
    "\n",
    "        # Remove participants who failed quality control\n",
    "        task_qc = tuple('sub-'+str(itm[0]) for itm in\n",
    "                        pd.read_csv(pjoin(cimaq_mar_dir, \\\n",
    "                                          'derivatives/CIMAQ_fmri_memory/data/participants/sub_list_TaskQC.tsv'),\n",
    "                              sep = '\\t').values)\n",
    "        subjects = subjects.iloc[[row[0] for row in subjects.iterrows()\n",
    "                                        if row[1].mar_subs in task_qc]]\n",
    "\n",
    "        # Select a random participant\n",
    "        self.sub_id = subjects.sample(1).values.flatten()\n",
    "        # Sort march scans and november scans in their respective DataFrames\n",
    "\n",
    "        mar_scans = lu.loadfiles([itm for itm in\n",
    "                                    lu.loadimages(pjoin(cimaq_mar_dir, self.sub_id[0]))\n",
    "                                    if not itm.endswith('.json')])\n",
    "        nov_scans = lu.loadfiles([itm for itm in\n",
    "                                    lu.loadimages(pjoin(cimaq_nov_dir, self.sub_id[1]))\n",
    "                                    if not itm.endswith('.json')])\n",
    "        self.mar_scans = df(((grp, mar_scans.groupby('parent').get_group(grp).fpaths.values)\n",
    "                             for grp in mar_scans.groupby('parent').groups)).set_index(0).T\n",
    "\n",
    "        self.nov_scans = df(((grp, nov_scans.groupby('parent').get_group(grp).fpaths.values)\n",
    "                             for grp in nov_scans.groupby('parent').groups)).set_index(0).T\n",
    "        \n",
    "        mar_infos = lu.loadfiles([itm for itm in\n",
    "                                    lu.loadimages(pjoin(cimaq_mar_dir, self.sub_id[0]))\n",
    "                                    if itm.endswith('.json')])\n",
    "        self.mar_infos = df(((grp, mar_infos.groupby('parent').get_group(grp))\n",
    "                             for grp in mar_infos.groupby('parent').groups))\n",
    "        nov_infos = lu.loadfiles([itm for itm in\n",
    "                                    lu.loadimages(pjoin(cimaq_nov_dir, self.sub_id[0]))\n",
    "                                    if itm.endswith('.json')])\n",
    "        self.nov_infos = df(((grp, nov_infos.groupby('parent').get_group(grp))\n",
    "                             for grp in nov_infos.groupby('parent').groups))\n",
    "#         self.mar_epi_mask = masking.compute_epi_mask(mean_img(concat_imgs(\n",
    "#                                 [[img if len(nib.load(img).shape) == 3\n",
    "#                                   else mean_img(img)][0]\n",
    "#                                  for img in self.mar_scans.fmap[1]],\n",
    "#                                 auto_resample=True)))\n",
    "#         self.mar_anat_mask = mean_img(concat_imgs(self.mar_scans.anat[1],\n",
    "#                                                     auto_resample = True))\n",
    "        # Load participant's events (in-scan) and behavioural (post-scan) task files\n",
    "\n",
    "        self.events = [pd.read_csv(pjoin(events_path, itm), sep = '\\t')\n",
    "                       for itm in lu.loadimages(events_path)\n",
    "                       if bname(itm).split('_')[1] == self.sub_id[0].split('-')[1]][0]\n",
    "        self.events['duration'] = [abs(row[1].stim_onset - row[1].fix_onset)\n",
    "                                   for row in self.events.iterrows()]\n",
    "        self.events = self.events.rename(columns = {'stim_onset': 'onset'})\n",
    "        self.events['trial_type'] = self.events['category']\n",
    "        self.behav = [pd.read_csv(pjoin(behav_path, itm), sep = '\\t')\n",
    "                      for itm in lu.loadimages(behav_path)\n",
    "                      if bname(itm).split('_')[1] == \\\n",
    "                      self.sub_id[1].split('-')[1]][0]\n",
    "        correctsources = self.events[['oldnumber', 'correctsource']]\n",
    "        self.behav['correctsource'] = correctsources.correctsource\n",
    "        self.behav['correctsource'] = [row[1].correctsource if row[1].oldnumber\n",
    "                                               in lst_intersection(self.events.oldnumber,\n",
    "                                                                   self.behav.oldnumber)\n",
    "                                               else np.nan for row in self.behav.iterrows()]\n",
    "        self.behav['spatial_acc'] = [row[1].spatial_resp == row[1].correctsource\n",
    "                                             for row in self.behav.iterrows()]\n",
    "        self.behav['recognition_acc'] = \\\n",
    "             self.behav['recognition_acc'].replace({0: False, 1: True})\n",
    "        self.behav.recognition_resp = \\\n",
    "             self.behav.recognition_resp.replace({1: 'old', 2:'new'})\n",
    "        recognition_accuracy = [row[1].category == row[1].recognition_resp\n",
    "                                for row in self.behav.iterrows()]\n",
    "        self.behav['recognition_acc'] = self.behav.recognition_resp.values == \\\n",
    "                                                  self.behav.category.values\n",
    "        def get_outcomes(behav):\n",
    "            ''' Compute behavioural (outside scanner) trial outcomes.\n",
    "                \"hit\" = successful object and position recognition\n",
    "                \"recog_ok_spatial_wrong\" = successful object recognition and\n",
    "                 wrong position recognition\n",
    "                \"false_alarm\" = new object misrecognized as old\n",
    "                \"corr_rejection\" = new object recognized as new\n",
    "                \"miss\" = old object misrecognized as new'''\n",
    "            responses = []\n",
    "            for row in behav.iterrows():\n",
    "                if row[1].recognition_acc and row[1].spatial_acc:\n",
    "                    responses.append('hit')\n",
    "                elif row[1].recognition_acc and not row[1].spatial_acc:\n",
    "                    responses.append('recog_ok_spatial_wrong')\n",
    "                elif row[1].category == 'new' and row[1].recognition_resp == 'old':\n",
    "                    responses.append('false_alarm')\n",
    "                elif row[1].category == 'new' and row[1].recognition_resp == 'new':\n",
    "                    responses.append('corr_rejection')\n",
    "                elif row[1].category == 'old' and row[1].recognition_resp == 'new':\n",
    "                    responses.append('miss')\n",
    "            return responses\n",
    "        outcomes = get_outcomes(self.behav)\n",
    "        self.behav['outcomes'] = outcomes\n",
    "        self.confounds = [pd.read_csv(itm, sep='\\t') for itm in\n",
    "                          lu.loadimages(pjoin(cimaq_mar_dir,\\\n",
    "                                              'derivatives/CIMAQ_fmri_memory/data/confounds/resample'))\n",
    "                          if bname(itm).split('_')[1][3:] == self.sub_id[0].split('-')[1]][0]\n",
    "\n",
    "        def get_tr_nscans_frametimes(\n",
    "            fpath:Union[str, os.PathLike]\n",
    "        ) -> tuple:\n",
    "            # repetition time is 2.5 seconds\n",
    "            tr = dict(nib.load(fpath).header)['pixdim'][4]\n",
    "            # the acquisition comprises 128 310\n",
    "            n_scans = dict(nib.load(fpath).header)['dim'][4]\n",
    "            # here are the correspoding frame times\n",
    "            frame_times = np.arange(n_scans) * tr\n",
    "            return tr, n_scans, frame_times\n",
    "        self.tr, self.n_scans, self.frame_times = \\\n",
    "             get_tr_nscans_frametimes(self.mar_scans.func[1][0])\n",
    "        self.resampled_frame_times=np.arange(0, self.frame_times.max(),\n",
    "                                             self.frame_times.max()/self.events.shape[0])\n",
    "        \n",
    "        def get_epi_mask_fromdata(imgs):\n",
    "            ''' Compute a nilearn.masking.compute_multi_epi_mask from all available epi data\n",
    "                Gets nilearn.image.mean_img for 3D images\n",
    "                If an epi image is 4D, then gets mean_img for each 3D vol outputed by\n",
    "                nilearn.image.iter_img(<4D_epi_img.nii.gz>), concatenates and auto resample\n",
    "                all obtained 3D volumes and iterates over each concatenated, resampled and averaged\n",
    "                3D volume to make the epi_imgs:list parameter to be passed to\n",
    "                nilearn.image.compute_multi_epi_mask\n",
    "\n",
    "                Parameters\n",
    "                ----------\n",
    "                imgs: list\n",
    "                List of nifti images paths\n",
    "                - valid epi images should contain the string \"_epi\" in their path\n",
    "            '''\n",
    "            all_resampled_epi_imgs = lu.flatten(list(nilearn.image.iter_img(nilearn.image.concat_imgs(\n",
    "                                          lu.flatten(list([mean_img(nilearn.image.load_img(img)) if \n",
    "                                                           len(nilearn.image.load_img(img).shape)==3\n",
    "                                                           else[mean_img(vol) for vol in\n",
    "                                                                nilearn.image.iter_img(nilearn.image.load_img(img))]]\n",
    "                                                          for img in imgs\n",
    "                                                          if '_epi' in img)), auto_resample=True))))\n",
    "            return nilearn.masking.compute_multi_epi_mask(epi_imgs=all_resampled_epi_imgs)\n",
    "        # Compute epi masks for march and november scans, respectively\n",
    "        self.mar_epi_mask = get_epi_mask_fromdata(imgs=self.mar_scans.fmap[1])\n",
    "        self.nov_epi_mask = get_epi_mask_fromdata(imgs=self.nov_scans.fmap[1])\n",
    "        \n",
    "#         self.full_epi_mask=get_epi_mask_fromdata(imgs=list(self.mar_scans.fmap[1])+\\\n",
    "#                                                  list(self.nov_scans.fmap[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trialnumber</th>\n",
       "      <th>category</th>\n",
       "      <th>trialcode</th>\n",
       "      <th>oldnumber</th>\n",
       "      <th>correctsource</th>\n",
       "      <th>stim_resp</th>\n",
       "      <th>stim_rt</th>\n",
       "      <th>stim_acc</th>\n",
       "      <th>onset</th>\n",
       "      <th>fix_onset</th>\n",
       "      <th>fix_duration</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>outcomes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>4.541</td>\n",
       "      <td>7.541</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>8.041</td>\n",
       "      <td>11.040</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.999</td>\n",
       "      <td>enc</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>922</td>\n",
       "      <td>0</td>\n",
       "      <td>11.540</td>\n",
       "      <td>14.540</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>enc</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "      <td>20.039</td>\n",
       "      <td>23.039</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc01</td>\n",
       "      <td>old61</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>23.539</td>\n",
       "      <td>26.539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>enc</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc75</td>\n",
       "      <td>old51</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>672</td>\n",
       "      <td>0</td>\n",
       "      <td>702.976</td>\n",
       "      <td>705.975</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.999</td>\n",
       "      <td>enc</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>716.474</td>\n",
       "      <td>719.474</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>ctl</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>118</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc76</td>\n",
       "      <td>old26</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>784</td>\n",
       "      <td>0</td>\n",
       "      <td>724.474</td>\n",
       "      <td>727.473</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.999</td>\n",
       "      <td>enc</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>119</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc77</td>\n",
       "      <td>old27</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>656</td>\n",
       "      <td>0</td>\n",
       "      <td>728.473</td>\n",
       "      <td>731.473</td>\n",
       "      <td>18.5</td>\n",
       "      <td>3.000</td>\n",
       "      <td>enc</td>\n",
       "      <td>miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>120</td>\n",
       "      <td>enc</td>\n",
       "      <td>enc78</td>\n",
       "      <td>old17</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>591</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>enc</td>\n",
       "      <td>hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trialnumber category trialcode oldnumber  correctsource  stim_resp  \\\n",
       "0              1      ctl      ctl0       NaN              5        2.0   \n",
       "1              2      enc     enc00       NaN              8        2.0   \n",
       "2              3      enc    enc000       NaN              9        2.0   \n",
       "3              4      ctl     ctl01       NaN              8        2.0   \n",
       "4              5      enc     enc01     old61              6        2.0   \n",
       "..           ...      ...       ...       ...            ...        ...   \n",
       "115          116      enc     enc75     old51              6        2.0   \n",
       "116          117      ctl     ctl39       NaN              9        2.0   \n",
       "117          118      enc     enc76     old26              5        2.0   \n",
       "118          119      enc     enc77     old27              5        2.0   \n",
       "119          120      enc     enc78     old17              8        2.0   \n",
       "\n",
       "     stim_rt  stim_acc    onset  fix_onset  fix_duration  duration trial_type  \\\n",
       "0        724         0    4.541      7.541           0.5     3.000        ctl   \n",
       "1        630         0    8.041     11.040           0.5     2.999        enc   \n",
       "2        922         0   11.540     14.540           5.5     3.000        enc   \n",
       "3       1386         0   20.039     23.039           0.5     3.000        ctl   \n",
       "4        858         0   23.539     26.539           1.0     3.000        enc   \n",
       "..       ...       ...      ...        ...           ...       ...        ...   \n",
       "115      672         0  702.976    705.975          10.5     2.999        enc   \n",
       "116      622         0  716.474    719.474           5.0     3.000        ctl   \n",
       "117      784         0  724.474    727.473           1.0     2.999        enc   \n",
       "118      656         0  728.473    731.473          18.5     3.000        enc   \n",
       "119      591         0      NaN        NaN           NaN       NaN        enc   \n",
       "\n",
       "                   outcomes  \n",
       "0                       ctl  \n",
       "1                       ctl  \n",
       "2                       ctl  \n",
       "3                       ctl  \n",
       "4    recog_ok_spatial_wrong  \n",
       "..                      ...  \n",
       "115  recog_ok_spatial_wrong  \n",
       "116                     ctl  \n",
       "117  recog_ok_spatial_wrong  \n",
       "118                    miss  \n",
       "119                     hit  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_data.events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default 2nd subject will be fetched\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import datasets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# haxby_dataset = datasets.fetch_haxby()\n",
    "subject_data = participant_data()\n",
    "# repetition has to be known\n",
    "TR = subject_data.tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 80, 41)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80, 80, 41)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80, 80, 41, 310)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(80, 80, 41, 310)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(subject_data.mar_epi_mask.shape,\n",
    "        subject_data.nov_epi_mask.shape,\n",
    "        nib.load(subject_data.mar_scans.func[1][0]).shape,\n",
    "        nib.load(subject_data.nov_scans.func[1][0]).shape,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fnadeau/../../data/cisl/DATA/cimaq_20190901/sub-7674650/ses-V03/func/sub-7674650_ses-V03_task-memory_bold.nii.gz',\n",
       " '/home/fnadeau/../../data/cisl/DATA/cimaq_20190901/sub-7674650/ses-V10/func/sub-7674650_ses-V10_task-memory_bold.nii.gz',\n",
       " '/home/fnadeau/../../data/cisl/DATA/cimaq_03-19/sub-729722/ses-4/func/sub-729722_ses-4_task-memory_bold.nii.gz']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(itm for itm in subject_data.nov_scans.func[1].tolist()+\\\n",
    "     subject_data.mar_scans.func[1].tolist()\n",
    "     if 'memory' in itm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the behavioral data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['rest', 'scissors', 'face', 'cat', 'shoe', 'house', 'scrambledpix',\n",
       "        'bottle', 'chair'], dtype=object),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# haxby_dataset = datasets.fetch_haxby()\n",
    "haxby_dataset = datasets.fetch_haxby(data_dir=xpu('~/../../data/cisl/DATA/nilearn_data/haxy'),\n",
    "                                     subjects=list(range(1,6)),\n",
    "                                     fetch_stimuli=True,\n",
    "                                     resume=True,\n",
    "                                     verbose=1)\n",
    "behavioral_haxby = pd.read_csv(haxby_dataset.session_target[0], sep=' ')\n",
    "behavioral_haxby.labels.unique(),behavioral_haxby.chunks.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iterating over fmri volumes: 100%|███████| 310/310 [00:00<00:00, 1189601.32it/s]\n",
      "resampling fmri volumes to epi mask affine and shape: 100%|█| 310/310 [00:25<00:\n"
     ]
    }
   ],
   "source": [
    "# Load target information as string and give a numerical identifier to each\n",
    "behavioral = subject_data.behav\n",
    "conditions = behavioral['outcomes'].values\n",
    "\n",
    "# Record these as an array of sessions\n",
    "sessions = behavioral['oldnumber'].values\n",
    "unique_sessions = behavioral['oldnumber'].unique()\n",
    "\n",
    "# fMRI data: a unique file for each session\n",
    "# func_filename = haxby_dataset.func[0]\n",
    "func_filename = subject_data.mar_scans.func[1][0]\n",
    "func_imgs=list(img for img in tqdm(list(nilearn.image.iter_img(\n",
    "                   subject_data.mar_scans.func[1][0])),\n",
    "                                      desc='iterating over fmri volumes'))\n",
    "resampled_func=[nilearn.image.resample_to_img(source_img=img,\n",
    "                                              target_img=subject_data.mar_epi_mask)\n",
    "                for img in tqdm(list(nilearn.image.iter_img(subject_data.mar_scans.func[1][0])),\n",
    "                                desc='resampling fmri volumes to epi mask affine and shape')]\n",
    "masked_func=nilearn.masking.apply_mask(imgs=resampled_func,\n",
    "                                          mask_img=subject_data.mar_epi_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grouping fmri volumes by events/trials: 100%|█| 120/120 [00:55<00:00,  2.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare fmri image file by resampling the time (4th) dimension to be the same as the number of trials\n",
    "decomp_func=df(zip(subject_data.frame_times,func_imgs,\n",
    "       resampled_func,masked_func),columns=['frame_times','func_imgs',\n",
    "                                            'resampled_func','masked_func'])\n",
    "test=df(pd.cut(decomp_func['frame_times'],\n",
    "               subject_data.events.shape[0]))\n",
    "test[['func_imgs','resampled_func','masked_func']] = \\\n",
    "    decomp_func[['func_imgs','resampled_func','masked_func']].values\n",
    "results = df(((grp, nilearn.image.mean_img(test.groupby('frame_times').get_group(grp)['resampled_func']),\n",
    "               test.groupby('frame_times').get_group(grp)['masked_func'],\n",
    "               nilearn.image.mean_img(test.groupby('frame_times').get_group(grp)['func_imgs']))\n",
    "              for grp in tqdm(list(test.groupby('frame_times').groups),\n",
    "                      desc='grouping fmri volumes by events/trials')),\n",
    "            columns=['intervals','grouped_resampled_func','grouped_masked_func','grouped_func_imgs'])\n",
    "resampled_frame_times=np.arange(0, subject_data.frame_times.max(),\n",
    "                                subject_data.frame_times.max()/subject_data.events.shape[0])\n",
    "subject_data.resampled_frame_times=resampled_frame_times\n",
    "subject_data.events.outcomes=subject_data.events.outcomes.fillna('ctl')\n",
    "results['resampled_frame_times']=subject_data.resampled_frame_times\n",
    "results=results.rename(columns={'func_imgs':'resampled_func_imgs'})\n",
    "newmatrix=pd.concat([results,subject_data.events],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['intervals', 'grouped_resampled_func', 'grouped_masked_func',\n",
       "       'grouped_func_imgs', 'resampled_frame_times', 'trialnumber', 'category',\n",
       "       'trialcode', 'oldnumber', 'correctsource', 'stim_resp', 'stim_rt',\n",
       "       'stim_acc', 'onset', 'fix_onset', 'fix_duration', 'duration',\n",
       "       'trial_type', 'outcomes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmatrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.437498</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.874995</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.312493</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.749990</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>740.312218</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>746.749715</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>753.187213</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>759.624710</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>766.062208</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>enc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          onset  duration trial_type\n",
       "0      0.000000       NaN        ctl\n",
       "1      6.437498  6.437498        enc\n",
       "2     12.874995  6.437498        enc\n",
       "3     19.312493  6.437498        ctl\n",
       "4     25.749990  6.437498        enc\n",
       "..          ...       ...        ...\n",
       "115  740.312218  6.437498        enc\n",
       "116  746.749715  6.437498        ctl\n",
       "117  753.187213  6.437498        enc\n",
       "118  759.624710  6.437498        enc\n",
       "119  766.062208  6.437498        enc\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmatrix.columns\n",
    "model_events=newmatrix[['oldnumber','resampled_frame_times','trial_type']]\n",
    "model_events['duration']=model_events['resampled_frame_times'].diff()\n",
    "model_events=model_events.rename(columns={'resampled_frame_times':'onset'})\n",
    "model_events[['onset','duration','trial_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    384\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: -1 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26623/3515090163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdrift_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cosine'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#         high_pass=0.01,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         drift_order=1)\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;31m#         fir_delays=[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#         add_regs=behav_design_matrix.iloc[:,:3],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36mmake_first_level_design_matrix\u001b[0;34m(frame_times, events, hrf_model, drift_model, high_pass, drift_order, fir_delays, add_regs, add_reg_names, min_onset, oversampling)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;31m# step 3: drifts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     drift, dnames = _make_drift(drift_model, frame_times, drift_order,\n\u001b[0;32m--> 377\u001b[0;31m                                 high_pass)\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36m_make_drift\u001b[0;34m(drift_model, frame_times, order, high_pass)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poly_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdrift_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cosine_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdrift_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_none_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36m_cosine_drift\u001b[0;34m(high_pass, frame_times)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mn_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mn_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhigh_pass\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         warn('High-pass filter will span all accessible frequencies '\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "# help(make_first_level_design_matrix)\n",
    "\n",
    "# smoothing fwhm value criterion\n",
    "'''\n",
    "Source: http://jpeelle.net/mri/image_processing/smoothing.html\n",
    "One common rule of thumb is that, to render your data approximately normal,\n",
    "you should smooth with a Gaussian filter approximately three times the size of your voxel.\n",
    "If your voxel size is 3 x 3 x 3 mm, you would smooth with a 9 mm FWHM Gaussian filter.\n",
    "'''\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "first_level_model = FirstLevelModel(t_r=subject_data.tr,\n",
    "                                    slice_time_ref=0.0,\n",
    "                                    hrf_model='glover',\n",
    "                                    drift_model='cosine',\n",
    "                                    high_pass=0.01,\n",
    "                                    drift_order=1,\n",
    "                                    fir_delays=[0],\n",
    "#                                     min_onset=subject_data.events.iloc[4].onset,\n",
    "#                                     mask_img=subject_data.mar_epi_mask,\n",
    "#                                     target_affine=subject_data.mar_epi_mask.affine,\n",
    "#                                     target_shape=subject_data.mar_epi_mask.shape,\n",
    "                                    smoothing_fwhm=dict(nib.load(subject_data.mar_scans.func[1][0]).header)['pixdim'][1]*3,\n",
    "#                                     memory=Memory(location=None),\n",
    "                                    memory_level=1,\n",
    "                                    standardize=True,\n",
    "                                    signal_scaling=0,\n",
    "                                    noise_model='ar1',\n",
    "                                    verbose=0, n_jobs=1,\n",
    "                                    minimize_memory=False,\n",
    "                                    subject_label=subject_data.sub_id[0])\n",
    "fmri_design_matrix = \\\n",
    "    make_first_level_design_matrix(\n",
    "        frame_times=newmatrix.resampled_frame_times,\n",
    "#         frame_times=np.arange(0, subject_data.frame_times.max(),\n",
    "#                                           subject_data.frame_times.max()/subject_data.events.shape[0]),\n",
    "        events=model_events[['onset','duration','trial_type']],\n",
    "        hrf_model='glover',\n",
    "        drift_model='cosine',\n",
    "#         high_pass=0.01,\n",
    "        drift_order=1)\n",
    "#         fir_delays=[0])\n",
    "#         add_regs=behav_design_matrix.iloc[:,:3],\n",
    "#         add_reg_names=list(behav_design_matrix.columns)[:3],\n",
    "#         oversampling=50)\n",
    "nilearn.plotting.plot_design_matrix(fmri_design_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0:      onset trial_type  duration\n",
       " 6     15.0   scissors       2.5\n",
       " 7     17.5   scissors       2.5\n",
       " 8     20.0   scissors       2.5\n",
       " 9     22.5   scissors       2.5\n",
       " 10    25.0   scissors       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0      chair       2.5\n",
       " 111  277.5      chair       2.5\n",
       " 112  280.0      chair       2.5\n",
       " 113  282.5      chair       2.5\n",
       " 114  285.0      chair       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 1:      onset    trial_type  duration\n",
       " 6     15.0          face       2.5\n",
       " 7     17.5          face       2.5\n",
       " 8     20.0          face       2.5\n",
       " 9     22.5          face       2.5\n",
       " 10    25.0          face       2.5\n",
       " ..     ...           ...       ...\n",
       " 110  275.0  scrambledpix       2.5\n",
       " 111  277.5  scrambledpix       2.5\n",
       " 112  280.0  scrambledpix       2.5\n",
       " 113  282.5  scrambledpix       2.5\n",
       " 114  285.0  scrambledpix       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 2:      onset trial_type  duration\n",
       " 6     15.0        cat       2.5\n",
       " 7     17.5        cat       2.5\n",
       " 8     20.0        cat       2.5\n",
       " 9     22.5        cat       2.5\n",
       " 10    25.0        cat       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0      house       2.5\n",
       " 111  277.5      house       2.5\n",
       " 112  280.0      house       2.5\n",
       " 113  282.5      house       2.5\n",
       " 114  285.0      house       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 3:      onset trial_type  duration\n",
       " 6     15.0       shoe       2.5\n",
       " 7     17.5       shoe       2.5\n",
       " 8     20.0       shoe       2.5\n",
       " 9     22.5       shoe       2.5\n",
       " 10    25.0       shoe       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0   scissors       2.5\n",
       " 111  277.5   scissors       2.5\n",
       " 112  280.0   scissors       2.5\n",
       " 113  282.5   scissors       2.5\n",
       " 114  285.0   scissors       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 4:      onset    trial_type  duration\n",
       " 6     15.0         house       2.5\n",
       " 7     17.5         house       2.5\n",
       " 8     20.0         house       2.5\n",
       " 9     22.5         house       2.5\n",
       " 10    25.0         house       2.5\n",
       " ..     ...           ...       ...\n",
       " 110  275.0  scrambledpix       2.5\n",
       " 111  277.5  scrambledpix       2.5\n",
       " 112  280.0  scrambledpix       2.5\n",
       " 113  282.5  scrambledpix       2.5\n",
       " 114  285.0  scrambledpix       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 5:      onset trial_type  duration\n",
       " 6     15.0      house       2.5\n",
       " 7     17.5      house       2.5\n",
       " 8     20.0      house       2.5\n",
       " 9     22.5      house       2.5\n",
       " 10    25.0      house       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0   scissors       2.5\n",
       " 111  277.5   scissors       2.5\n",
       " 112  280.0   scissors       2.5\n",
       " 113  282.5   scissors       2.5\n",
       " 114  285.0   scissors       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 6:      onset trial_type  duration\n",
       " 6     15.0       face       2.5\n",
       " 7     17.5       face       2.5\n",
       " 8     20.0       face       2.5\n",
       " 9     22.5       face       2.5\n",
       " 10    25.0       face       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0     bottle       2.5\n",
       " 111  277.5     bottle       2.5\n",
       " 112  280.0     bottle       2.5\n",
       " 113  282.5     bottle       2.5\n",
       " 114  285.0     bottle       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 7:      onset trial_type  duration\n",
       " 6     15.0       face       2.5\n",
       " 7     17.5       face       2.5\n",
       " 8     20.0       face       2.5\n",
       " 9     22.5       face       2.5\n",
       " 10    25.0       face       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0      house       2.5\n",
       " 111  277.5      house       2.5\n",
       " 112  280.0      house       2.5\n",
       " 113  282.5      house       2.5\n",
       " 114  285.0      house       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 8:      onset trial_type  duration\n",
       " 6     15.0       face       2.5\n",
       " 7     17.5       face       2.5\n",
       " 8     20.0       face       2.5\n",
       " 9     22.5       face       2.5\n",
       " 10    25.0       face       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0   scissors       2.5\n",
       " 111  277.5   scissors       2.5\n",
       " 112  280.0   scissors       2.5\n",
       " 113  282.5   scissors       2.5\n",
       " 114  285.0   scissors       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 9:      onset trial_type  duration\n",
       " 6     15.0       face       2.5\n",
       " 7     17.5       face       2.5\n",
       " 8     20.0       face       2.5\n",
       " 9     22.5       face       2.5\n",
       " 10    25.0       face       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0     bottle       2.5\n",
       " 111  277.5     bottle       2.5\n",
       " 112  280.0     bottle       2.5\n",
       " 113  282.5     bottle       2.5\n",
       " 114  285.0     bottle       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 10:      onset trial_type  duration\n",
       " 6     15.0        cat       2.5\n",
       " 7     17.5        cat       2.5\n",
       " 8     20.0        cat       2.5\n",
       " 9     22.5        cat       2.5\n",
       " 10    25.0        cat       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0   scissors       2.5\n",
       " 111  277.5   scissors       2.5\n",
       " 112  280.0   scissors       2.5\n",
       " 113  282.5   scissors       2.5\n",
       " 114  285.0   scissors       2.5\n",
       " \n",
       " [72 rows x 3 columns],\n",
       " 11:      onset trial_type  duration\n",
       " 6     15.0     bottle       2.5\n",
       " 7     17.5     bottle       2.5\n",
       " 8     20.0     bottle       2.5\n",
       " 9     22.5     bottle       2.5\n",
       " 10    25.0     bottle       2.5\n",
       " ..     ...        ...       ...\n",
       " 110  275.0   scissors       2.5\n",
       " 111  277.5   scissors       2.5\n",
       " 112  280.0   scissors       2.5\n",
       " 113  282.5   scissors       2.5\n",
       " 114  285.0   scissors       2.5\n",
       " \n",
       " [72 rows x 3 columns]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavioral = pd.read_csv(haxby_dataset.session_target[0], sep=' ')\n",
    "\n",
    "def get_events(behavioral,\n",
    "               TR:float=2.5) -> dict:\n",
    "    conditions = behavioral['labels'].values\n",
    "\n",
    "    # Record these as an array of sessions\n",
    "    sessions = behavioral['chunks'].values\n",
    "    unique_sessions = behavioral['chunks'].unique()\n",
    "\n",
    "    # fMRI data: a unique file for each session\n",
    "    func_filename = haxby_dataset.func[0]\n",
    "    events = {}\n",
    "    # events will take  the form of a dictionary of Dataframes, one per session\n",
    "    for session in unique_sessions:\n",
    "        # get the condition label per session\n",
    "        conditions_session = conditions[sessions == session]\n",
    "        # get the number of scans per session, then the corresponding\n",
    "        # vector of frame times\n",
    "        n_scans = len(conditions_session)\n",
    "        frame_times = TR * np.arange(n_scans)\n",
    "        # each event last the full TR\n",
    "        duration = TR * np.ones(n_scans)\n",
    "        # Define the events object\n",
    "        events_ = pd.DataFrame(\n",
    "            {'onset': frame_times,\n",
    "             'trial_type': conditions_session,\n",
    "             'duration': duration})\n",
    "        # remove the rest condition and insert into the dictionary\n",
    "        events[session] = events_[events_.trial_type != 'rest']\n",
    "    return events,sessions,unique_sessions\n",
    "events,sessions,unique_sessions=get_events(behavioral)\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events01=subject_data.events.copy()\n",
    "# events01['intervals']=list(decomp_func.intervals.unique())\n",
    "# outcomes_map=dict(zip(events01.intervals,events01.outcomes))\n",
    "# oldnumber_map=dict(zip(events01.intervals,events01.oldnumber))\n",
    "# duration_map=dict(zip(events01.intervals,events01.duration))\n",
    "# onset_map=dict(zip(events01.intervals,events01.onset))\n",
    "# maps=tuple((col,dict(zip(events01.intervals,events01[col].values)))\n",
    "#                 for col in list(col for col in\n",
    "#                                 events01.columns\n",
    "#                                 if col != 'intervals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a proper event structure for each session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events = {}\n",
    "# # events will take  the form of a dictionary of Dataframes, one per session\n",
    "# for session in unique_sessions:\n",
    "#     # get the condition label per session\n",
    "#     conditions_session = conditions[sessions == session]\n",
    "#     # get the number of scans per session, then the corresponding\n",
    "#     # vector of frame times\n",
    "#     n_scans = len(conditions_session)\n",
    "# #     frame_times = TR * np.arange(n_scans)\n",
    "#     frame_times = subject_data.frame_times\n",
    "#     # each event last the full TR\n",
    "#     duration = TR * np.ones(n_scans)\n",
    "#     # Define the events object\n",
    "#     events_ = pd.DataFrame(\n",
    "#         {'onset': frame_times, 'trial_type': conditions_session, 'duration': duration})\n",
    "#     # remove the rest condition and insert into the dictionary\n",
    "#     events[session] = events_[events_.trial_type != 'rest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nilearn.image import index_img\n",
    "# import pandas as pd\n",
    "# from nilearn import datasets\n",
    "# from nilearn.image import new_img_like, load_img, get_data\n",
    "\n",
    "# fmri_filename = subject_data.mar_scans.func[1][0]\n",
    "# # labels = pd.read_csv(haxby_dataset.session_target[0], sep=\" \")\n",
    "# labels = subject_data.behav[['oldnumber', 'outcomes']]\n",
    "# y = labels['outcomes']\n",
    "# session = labels['oldnumber']\n",
    "\n",
    "# condition_mask = y.isin(y.unique().tolist())\n",
    "\n",
    "# # Prepare fmri image file by resampling the time (4th) dimension to be the same as the number of trials\n",
    "# decomp_func = df(img for img in nilearn.image.iter_img(subject_data.mar_scans.func[1][0]))\n",
    "# decomp_func['frame_times'] = subject_data.frame_times\n",
    "# test=df(pd.cut(decomp_func['frame_times'], subject_data.events.shape[0]))\n",
    "# test['imgs'] = decomp_func[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = test.rename(columns={'frame_times': 'frame_intervals'})\n",
    "# test['frame_times'] = [val.mid for val in test.frame_intervals.values]\n",
    "# # test['intervals_duration'] = test.frame_intervals.diff()\n",
    "# test.frame_times.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "binned_fmri_image = nilearn.image.concat_imgs(grouped['nifti_imgs'].values,\n",
    "                                              auto_resample=True)\n",
    "fmri_img = index_img(binned_fmri_image, condition_mask)\n",
    "y, session = y[condition_mask], session[condition_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old64':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old10':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old26':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old77':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old63':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old50':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old39':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " nan: Empty DataFrame\n",
       " Columns: [onset, trial_type, duration]\n",
       " Index: [],\n",
       " 'old43':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old20':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old27':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old07':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old19':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old78':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5,\n",
       " 'old21':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old31':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old29':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5,\n",
       " 'old16':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old03':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old41':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old68':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old53':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old74':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old08':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old05':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old52':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old56':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old42':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old14':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old38':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old62':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old06':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old73':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old15':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old17':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old72':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old11':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old01':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old44':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old54':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old61':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old76':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old65':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old23':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5,\n",
       " 'old37':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old25':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old34':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old28':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old02':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old51':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old49':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old12':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old47':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old58':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5,\n",
       " 'old40':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old60':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old33':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old57':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old71':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5\n",
       " 2    5.0        hit       2.5,\n",
       " 'old59':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old55':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old04':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old32':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old67':    onset   trial_type  duration\n",
       " 0    0.0  false_alarm       2.5\n",
       " 1    2.5  false_alarm       2.5,\n",
       " 'old75':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old70':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5,\n",
       " 'old66':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old09':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old13':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old36':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old48':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old30':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5,\n",
       " 'old24':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old69':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old46':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old45':    onset              trial_type  duration\n",
       " 0    0.0  recog_ok_spatial_wrong       2.5\n",
       " 1    2.5  recog_ok_spatial_wrong       2.5\n",
       " 2    5.0  recog_ok_spatial_wrong       2.5,\n",
       " 'old18':    onset trial_type  duration\n",
       " 0    0.0        hit       2.5\n",
       " 1    2.5        hit       2.5,\n",
       " 'old35':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5,\n",
       " 'old22':    onset trial_type  duration\n",
       " 0    0.0       miss       2.5\n",
       " 1    2.5       miss       2.5\n",
       " 2    5.0       miss       2.5}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_events(behavioral,TR:float=2.5):\n",
    "#     conditions = behavioral['outcomes'].values\n",
    "\n",
    "#     # Record these as an array of sessions\n",
    "#     sessions = behavioral['oldnumber'].values\n",
    "#     unique_sessions = behavioral['oldnumber'].unique()\n",
    "\n",
    "#     # fMRI data: a unique file for each session\n",
    "#     func_filename = haxby_dataset.func[0]\n",
    "#     events = {}\n",
    "#     # events will take  the form of a dictionary of Dataframes, one per session\n",
    "#     for session in unique_sessions:\n",
    "#         # get the condition label per session\n",
    "#         conditions_session = conditions[sessions == session]\n",
    "#         # get the number of scans per session, then the corresponding\n",
    "#         # vector of frame times\n",
    "#         n_scans = len(conditions_session)\n",
    "#         frame_times = TR * np.arange(n_scans)\n",
    "#         # each event last the full TR\n",
    "#         duration = TR * np.ones(n_scans)\n",
    "#         # Define the events object\n",
    "#         events_ = pd.DataFrame(\n",
    "#             {'onset': frame_times,\n",
    "#              'trial_type': conditions_session,\n",
    "#              'duration': duration})\n",
    "#         # remove the rest condition and insert into the dictionary\n",
    "#         events[session] = events_[events_.trial_type != 'rest']\n",
    "#     return events,sessions,unique_sessions\n",
    "# events,sessions,unique_sessions=get_events(decomp_func02)\n",
    "# events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.437498</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.874995</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.312493</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.749990</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>740.312218</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>746.749715</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>ctl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>753.187213</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>recog_ok_spatial_wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>759.624710</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>766.062208</td>\n",
       "      <td>6.437498</td>\n",
       "      <td>hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          onset  duration              trial_type\n",
       "0      0.000000       NaN                     ctl\n",
       "1      6.437498  6.437498                     ctl\n",
       "2     12.874995  6.437498                     ctl\n",
       "3     19.312493  6.437498                     ctl\n",
       "4     25.749990  6.437498  recog_ok_spatial_wrong\n",
       "..          ...       ...                     ...\n",
       "115  740.312218  6.437498  recog_ok_spatial_wrong\n",
       "116  746.749715  6.437498                     ctl\n",
       "117  753.187213  6.437498  recog_ok_spatial_wrong\n",
       "118  759.624710  6.437498                    miss\n",
       "119  766.062208  6.437498                     hit\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmatrix.outcomes=newmatrix.outcomes.fillna('ctl')\n",
    "df(zip(newmatrix.resampled_frame_times,\n",
    "    newmatrix.resampled_frame_times.diff(),\n",
    "    newmatrix.outcomes),columns=['onset','duration','trial_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate and run FirstLevelModel\n",
    "\n",
    "We generate a list of z-maps together with their session and condition index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the glm on data from each session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███▉                                        | 7/79 [00:17<02:58,  2.48s/it]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18279/1659935675.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# fit the glm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mglm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfmri_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# set up contrasts: one per condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, run_imgs, events, confounds, design_matrices, bins)\u001b[0m\n\u001b[1;32m    550\u001b[0m                                                         \u001b[0mconfounds_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                                                         \u001b[0mconfounds_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_onset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m                                                         )\n\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36mmake_first_level_design_matrix\u001b[0;34m(frame_times, events, hrf_model, drift_model, high_pass, drift_order, fir_delays, add_regs, add_reg_names, min_onset, oversampling)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;31m# step 3: drifts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m     drift, dnames = _make_drift(drift_model, frame_times, drift_order,\n\u001b[0;32m--> 377\u001b[0;31m                                 high_pass)\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36m_make_drift\u001b[0;34m(drift_model, frame_times, order, high_pass)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poly_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdrift_model\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cosine'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cosine_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhigh_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdrift_model\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mdrift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_none_drift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/design_matrix.py\u001b[0m in \u001b[0;36m_cosine_drift\u001b[0;34m(high_pass, frame_times)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mn_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mn_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe_times\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_frames\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhigh_pass\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         warn('High-pass filter will span all accessible frequencies '\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "from nilearn.image import index_img\n",
    "for session in tqdm(unique_sessions):\n",
    "    # grab the fmri data for that particular session\n",
    "    fmri_session = index_img(func_filename, sessions == session)\n",
    "\n",
    "    # fit the glm\n",
    "    first_level_model.fit(fmri_session, events=events[session])\n",
    "\n",
    "    # set up contrasts: one per condition\n",
    "    conditions = events[session].trial_type.unique()\n",
    "    for condition_ in conditions:\n",
    "        z_maps.append(glm.compute_contrast(condition_))\n",
    "        conditions_label.append(condition_)\n",
    "        session_label.append(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a report\n",
    "Since we have already computed the FirstLevelModel\n",
    "and have the contrast, we can quickly create a summary report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported format character 'n' (0x6e) at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18279/3680939982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m report = make_glm_report(glm,\n\u001b[1;32m      5\u001b[0m                          \u001b[0mcontrasts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconditions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                          \u001b[0mbg_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmean_img_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                          )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/reporting/glm_reporter.py\u001b[0m in \u001b[0;36mmake_glm_report\u001b[0;34m(model, contrasts, title, bg_img, threshold, alpha, cluster_threshold, height_control, two_sided, min_distance, plot_type, display_mode, report_dims)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                                    \u001b[0msparsify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                                                    )\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mstatistical_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_stat_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrasts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mhtml_design_matrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dmtx_to_svg_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign_matrices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mmask_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasker_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_img_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/reporting/glm_reporter.py\u001b[0m in \u001b[0;36m_make_stat_maps\u001b[0;34m(model, contrasts)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \"\"\"\n\u001b[1;32m    514\u001b[0m     statistical_maps = {contrast_id: model.compute_contrast(contrast_val)\n\u001b[0;32m--> 515\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mcontrast_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                         }\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstatistical_maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/reporting/glm_reporter.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \"\"\"\n\u001b[1;32m    514\u001b[0m     statistical_maps = {contrast_id: model.compute_contrast(contrast_val)\n\u001b[0;32m--> 515\u001b[0;31m                         \u001b[0;32mfor\u001b[0m \u001b[0mcontrast_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrast_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontrasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m                         }\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstatistical_maps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/nilearn/glm/first_level/first_level.py\u001b[0m in \u001b[0;36mcompute_contrast\u001b[0;34m(self, contrast_def, stat_type, output_type)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_contrasts\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m             raise ValueError('%n contrasts given, while there are %n runs' %\n\u001b[0;32m--> 656\u001b[0;31m                              (n_contrasts, n_runs))\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# Translate formulas to vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported format character 'n' (0x6e) at index 1"
     ]
    }
   ],
   "source": [
    "from nilearn.image import mean_img\n",
    "from nilearn.reporting import make_glm_report\n",
    "mean_img_ = mean_img(func_filename)\n",
    "report = make_glm_report(glm,\n",
    "                         contrasts=conditions,\n",
    "                         bg_img=mean_img_,\n",
    "                         )\n",
    "\n",
    "report  # This report can be viewed in a notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a jupyter notebook, the report will be automatically inserted, as above.\n",
    "We have several other ways to access the report:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report.save_as_html('report.html')\n",
    "# report.open_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the decoding pipeline\n",
    "To define the decoding pipeline we use Decoder object, we choose :\n",
    "\n",
    "    * a prediction model, here a Support Vector Classifier, with a linear\n",
    "      kernel\n",
    "\n",
    "    * the mask to use, here a ventral temporal ROI in the visual cortex\n",
    "\n",
    "    * although it usually helps to decode better, z-maps time series don't\n",
    "      need to be rescaled to a 0 mean, variance of 1 so we use\n",
    "      standardize=False.\n",
    "\n",
    "    * we use univariate feature selection to reduce the dimension of the\n",
    "      problem keeping only 5% of voxels which are most informative.\n",
    "\n",
    "    * a cross-validation scheme, here we use LeaveOneGroupOut\n",
    "      cross-validation on the sessions which corresponds to a\n",
    "      leave-one-session-out\n",
    "\n",
    "We fit directly this pipeline on the Niimgs outputs of the GLM, with\n",
    "corresponding conditions labels and session labels (for the cross validation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "decoder = Decoder(estimator='svc', mask=haxby_dataset.mask, standardize=False,\n",
    "                  screening_percentile=5, cv=LeaveOneGroupOut())\n",
    "decoder.fit(z_maps, conditions_label, groups=session_label)\n",
    "\n",
    "# Return the corresponding mean prediction accuracy compared to chance\n",
    "\n",
    "classification_accuracy = np.mean(list(decoder.cv_scores_.values()))\n",
    "chance_level = 1. / len(np.unique(conditions))\n",
    "print('Classification accuracy: {:.4f} / Chance level: {}'.format(\n",
    "    classification_accuracy, chance_level))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
